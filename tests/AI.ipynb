{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -U langgraph langchain-community langchain-openai tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "import subprocess\n",
    "\n",
    "shell = subprocess.Popen(\"/bin/bash\", shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "\n",
    "@tool\n",
    "def terminal(command: str) -> str:\n",
    "    \"\"\"Executes the given command in a terminal and returns the output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    command : str\n",
    "        The command that gets executed in the terminal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        the return code of the terminal, 0 means successful execution\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nExecuting command: {command}\")\n",
    "    # Send command to the shell\n",
    "    shell.stdin.write(command + \"\\n\")\n",
    "    shell.stdin.flush()\n",
    "\n",
    "    # Wait for the command to finish and capture its output\n",
    "    shell.stdin.write(\"echo $? > /tmp/last_exit_code\\n\")\n",
    "    #shell.stdin.flush()\n",
    "    shell.stdin.write(\"cat /tmp/last_exit_code\\n\")\n",
    "    shell.stdin.flush()\n",
    "\n",
    "    # Read command output until EOF (or next prompt)\n",
    "    stdout_lines = []\n",
    "    stderr_lines = []\n",
    "    while True:\n",
    "        line = shell.stdout.readline()\n",
    "        stdout_lines.append(line)\n",
    "        \n",
    "        # print(shell.stdout,shell.stderr)\n",
    "        if line.startswith(\"0\") or line.startswith(\"1\") or line== (''):\n",
    "            break\n",
    "\n",
    "        \n",
    "    print(\"\".join(stdout_lines))\n",
    "\n",
    "    return \"\".join(stdout_lines)\n",
    "\n",
    "tools = [terminal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are an AI Assistant executing terminal commands based on given instructions. After each execution you report the success or result.\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{conversation}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# # # Get the prompt to use - you can modify this!\n",
    "# prompt = hub.pull(\"ih/ih-react-agent-executor\")\n",
    "# prompt.pretty_print()\n",
    "\n",
    "prompt = ChatPromptTemplate([(\"system\", \"You are an AI Assistant executing terminal commands based on given instructions. After each execution you report the success or result.\"), (\"placeholder\", \"{conversation}\")])\n",
    "prompt.pretty_print()\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "agent_executor = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\"\"\"\n",
    "First, we will need to track the current plan. Let's represent that as a list of strings.\n",
    "Next, we should track previously executed steps. Let's represent that as a list of tuples (these tuples will contain the step and then the result)\n",
    "Finally, we need to have some state to represent the final response as well as the original input.\n",
    "\"\"\"\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow in future\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(\n",
    "        description=\"different steps to follow, should be in sorted order\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "# This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "# The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\"\n",
    "\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"For the given task, create a simple, step-by-step execution plan for an AI agent executing terminal commands. \\\n",
    "                Each step should correspond to a specific command or action derived from the task that can be solved within the terminal. Ensure that each step is self-contained, \\\n",
    "                with all necessary details provided for successful execution. Avoid adding unnecessary steps or overly verbose descriptions. Opening or closing the terminal should not be part of this list.\\\n",
    "                The result of the final step should fulfill the objective outlined in the prompt. Ensure clarity and correctness to prevent missteps.\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "planner = planner_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o\", temperature=0\n",
    ").with_structured_output(Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "\n",
    "\n",
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For the given tutorial or guide, update the step-by-step execution plan based on progress made so far. \\\n",
    "Each step should represent a specific command or action still required to complete the objective. Ensure that each step is self-contained, \\\n",
    "clear, and provides all necessary details for successful execution. Avoid repeating already completed steps or adding unnecessary ones.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently completed the following steps:\n",
    "{past_steps}\n",
    "\n",
    "Update the plan accordingly. If no further steps are needed and the objective is complete, indicate that. Otherwise, provide the remaining steps that still NEED to be done.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "replanner = replanner_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o\", temperature=0\n",
    ").with_structured_output(Act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import END\n",
    "\n",
    "\n",
    "async def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan: {plan_str}\\n\\nYou are tasked with executing step {1}, {task}\\n \\n Report the status of the execution.\"\"\"\n",
    "    agent_response = await agent_executor.ainvoke(\n",
    "        {\"messages\": [(\"user\", task_formatted)]}\n",
    "    )\n",
    "\n",
    "    print(f\"Agent response: {agent_response['messages']} \\n\")\n",
    "\n",
    "    # for chunk in agent_response['messages']:\n",
    "    #     print(chunk)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)],\n",
    "    }\n",
    "\n",
    "\n",
    "async def plan_step(state: PlanExecute):\n",
    "    plan = await planner.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    return {\"plan\": plan.steps}\n",
    "\n",
    "\n",
    "async def replan_step(state: PlanExecute):\n",
    "    output = await replanner.ainvoke(state)\n",
    "    print(f\"Replanner: {output}\")\n",
    "    if isinstance(output.action, Response):\n",
    "        return {\"response\": output.action.response}\n",
    "    else:\n",
    "        return {\"plan\": output.action.steps}\n",
    "\n",
    "\n",
    "def should_end(state: PlanExecute):\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return END\n",
    "    else:\n",
    "        return \"agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# Add the plan node\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "\n",
    "# Add the execution step\n",
    "workflow.add_node(\"agent\", execute_step)\n",
    "\n",
    "# Add a replan node\n",
    "workflow.add_node(\"replan\", replan_step)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "# From plan we go to agent\n",
    "workflow.add_edge(\"planner\", \"agent\")\n",
    "\n",
    "# From agent, we replan\n",
    "workflow.add_edge(\"agent\", \"replan\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"replan\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_end,\n",
    "    [\"agent\", END],\n",
    ")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan': [\"Run the command 'python3.12 --version' to check if Python 3.12 is installed and to display its version number if it is.\"]}\n",
      "\n",
      "Executing command: python3.12 --version\n",
      "Agent response: [HumanMessage(content=\"For the following plan: 1. Run the command 'python3.12 --version' to check if Python 3.12 is installed and to display its version number if it is.\\n\\nYou are tasked with executing step 1, Run the command 'python3.12 --version' to check if Python 3.12 is installed and to display its version number if it is.\\n \\n Report the status of the execution.\", additional_kwargs={}, response_metadata={}, id='65a40a1d-2d79-4b8a-9937-d2ae65f5e5cf'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uSSke7Vu9zqejoaBdyeS4Hwk', 'function': {'arguments': '{\"command\":\"python3.12 --version\"}', 'name': 'terminal'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 176, 'total_tokens': 195, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a6ef43db-d99c-4343-8291-658cbc709482-0', tool_calls=[{'name': 'terminal', 'args': {'command': 'python3.12 --version'}, 'id': 'call_uSSke7Vu9zqejoaBdyeS4Hwk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 19, 'total_tokens': 195, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"Error: OSError(22, 'Invalid argument')\\n Please fix your mistakes.\", name='terminal', id='94127557-4273-4195-bd3d-4578f0a212cb', tool_call_id='call_uSSke7Vu9zqejoaBdyeS4Hwk', status='error'), AIMessage(content='It seems there was an error executing the command. The error message indicates an \"Invalid argument,\" which might be due to the environment not supporting the execution of terminal commands directly. \\n\\nIf you have access to a terminal, you can try running the command `python3.12 --version` directly there to check if Python 3.12 is installed and to display its version number.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 218, 'total_tokens': 296, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None}, id='run-3fed79fc-4f2e-48a6-b132-c57e74bc3b36-0', usage_metadata={'input_tokens': 218, 'output_tokens': 78, 'total_tokens': 296, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})] \n",
      "\n",
      "{'past_steps': [(\"Run the command 'python3.12 --version' to check if Python 3.12 is installed and to display its version number if it is.\", 'It seems there was an error executing the command. The error message indicates an \"Invalid argument,\" which might be due to the environment not supporting the execution of terminal commands directly. \\n\\nIf you have access to a terminal, you can try running the command `python3.12 --version` directly there to check if Python 3.12 is installed and to display its version number.')]}\n",
      "Replanner: action=Plan(steps=['Open a terminal on your computer.', \"Run the command 'python3.12 --version' in the terminal to check if Python 3.12 is installed.\", 'If Python 3.12 is not installed, download and install it from the official Python website.', \"After installation, verify the installation by running 'python3.12 --version' again in the terminal.\"])\n",
      "{'plan': ['Open a terminal on your computer.', \"Run the command 'python3.12 --version' in the terminal to check if Python 3.12 is installed.\", 'If Python 3.12 is not installed, download and install it from the official Python website.', \"After installation, verify the installation by running 'python3.12 --version' again in the terminal.\"]}\n",
      "\n",
      "Executing command: echo 'Terminal opened successfully'\n",
      "Agent response: [HumanMessage(content=\"For the following plan: 1. Open a terminal on your computer.\\n2. Run the command 'python3.12 --version' in the terminal to check if Python 3.12 is installed.\\n3. If Python 3.12 is not installed, download and install it from the official Python website.\\n4. After installation, verify the installation by running 'python3.12 --version' again in the terminal.\\n\\nYou are tasked with executing step 1, Open a terminal on your computer.\\n \\n Report the status of the execution.\", additional_kwargs={}, response_metadata={}, id='a1c33bb4-5da7-404c-b881-5110a2bfdd7d'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TQilwTo4QhosqHFzVkMvLaUh', 'function': {'arguments': '{\"command\":\"echo \\'Terminal opened successfully\\'\"}', 'name': 'terminal'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 200, 'total_tokens': 219, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-673fe945-38a0-43b8-9e61-2d503025b2a9-0', tool_calls=[{'name': 'terminal', 'args': {'command': \"echo 'Terminal opened successfully'\"}, 'id': 'call_TQilwTo4QhosqHFzVkMvLaUh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 200, 'output_tokens': 19, 'total_tokens': 219, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"Error: OSError(22, 'Invalid argument')\\n Please fix your mistakes.\", name='terminal', id='24c1488b-7c2d-40ca-98e0-0804493ec5b3', tool_call_id='call_TQilwTo4QhosqHFzVkMvLaUh', status='error'), AIMessage(content='It seems there was an error while trying to simulate opening a terminal. However, in a real-world scenario, you would open a terminal on your computer by using the terminal application available on your operating system. \\n\\nIf you need further assistance with the next steps, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 242, 'total_tokens': 300, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None}, id='run-3b977d5e-d954-42cb-afab-51fa856966d7-0', usage_metadata={'input_tokens': 242, 'output_tokens': 58, 'total_tokens': 300, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})] \n",
      "\n",
      "{'past_steps': [('Open a terminal on your computer.', 'It seems there was an error while trying to simulate opening a terminal. However, in a real-world scenario, you would open a terminal on your computer by using the terminal application available on your operating system. \\n\\nIf you need further assistance with the next steps, feel free to ask!')]}\n",
      "Replanner: action=Plan(steps=['If Python 3.12 is not installed, download and install it from the official Python website.', \"After installation, verify the installation by running 'python3.12 --version' again in the terminal.\"])\n",
      "{'plan': ['If Python 3.12 is not installed, download and install it from the official Python website.', \"After installation, verify the installation by running 'python3.12 --version' again in the terminal.\"]}\n",
      "\n",
      "Executing command: python3.12 --version\n",
      "\n",
      "Executing command: python3.12 --version\n",
      "\n",
      "Executing command: wget https://www.python.org/ftp/python/3.12.0/Python-3.12.0.tgz && tar -xvf Python-3.12.0.tgz && cd Python-3.12.0 && ./configure && make && sudo make install\n",
      "Agent response: [HumanMessage(content=\"For the following plan: 1. If Python 3.12 is not installed, download and install it from the official Python website.\\n2. After installation, verify the installation by running 'python3.12 --version' again in the terminal.\\n\\nYou are tasked with executing step 1, If Python 3.12 is not installed, download and install it from the official Python website.\\n \\n Report the status of the execution.\", additional_kwargs={}, response_metadata={}, id='9e832be9-1d19-4af6-b801-0abd9dbaa9a5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0Y01Gr7oH6jEpHGCs30XsR4Z', 'function': {'arguments': '{\"command\":\"python3.12 --version\"}', 'name': 'terminal'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 177, 'total_tokens': 196, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cd6c9115-f1e3-466c-831a-1802a4d22ced-0', tool_calls=[{'name': 'terminal', 'args': {'command': 'python3.12 --version'}, 'id': 'call_0Y01Gr7oH6jEpHGCs30XsR4Z', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 19, 'total_tokens': 196, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"Error: OSError(22, 'Invalid argument')\\n Please fix your mistakes.\", name='terminal', id='99b37000-7bb5-4f5b-beeb-d0b8cb508be6', tool_call_id='call_0Y01Gr7oH6jEpHGCs30XsR4Z', status='error'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Ot9z4BVsw2GqovGA459m842k', 'function': {'arguments': '{\"command\":\"python3.12 --version\"}', 'name': 'terminal'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 219, 'total_tokens': 238, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-37f6f1dd-76e1-4d66-9129-df9890ccd488-0', tool_calls=[{'name': 'terminal', 'args': {'command': 'python3.12 --version'}, 'id': 'call_Ot9z4BVsw2GqovGA459m842k', 'type': 'tool_call'}], usage_metadata={'input_tokens': 219, 'output_tokens': 19, 'total_tokens': 238, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"Error: OSError(22, 'Invalid argument')\\n Please fix your mistakes.\", name='terminal', id='53a8b648-119b-48e3-8e58-8078c58f8e6a', tool_call_id='call_Ot9z4BVsw2GqovGA459m842k', status='error'), AIMessage(content='It seems there is an issue with checking the Python 3.12 version using the command `python3.12 --version`. This could be due to Python 3.12 not being installed or an issue with the command execution environment. \\n\\nTo proceed, I will attempt to download and install Python 3.12 from the official Python website.', additional_kwargs={'tool_calls': [{'id': 'call_LKg25ViMTZCR1i1Mw08W8oxl', 'function': {'arguments': '{\"command\":\"wget https://www.python.org/ftp/python/3.12.0/Python-3.12.0.tgz && tar -xvf Python-3.12.0.tgz && cd Python-3.12.0 && ./configure && make && sudo make install\"}', 'name': 'terminal'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 141, 'prompt_tokens': 261, 'total_tokens': 402, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d82e9b12-48e3-4407-be31-f82e7c0eb10a-0', tool_calls=[{'name': 'terminal', 'args': {'command': 'wget https://www.python.org/ftp/python/3.12.0/Python-3.12.0.tgz && tar -xvf Python-3.12.0.tgz && cd Python-3.12.0 && ./configure && make && sudo make install'}, 'id': 'call_LKg25ViMTZCR1i1Mw08W8oxl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 261, 'output_tokens': 141, 'total_tokens': 402, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"Error: OSError(22, 'Invalid argument')\\n Please fix your mistakes.\", name='terminal', id='74daadbc-e7e7-4f98-8304-f54bb09d31fe', tool_call_id='call_LKg25ViMTZCR1i1Mw08W8oxl', status='error'), AIMessage(content='It seems there is a persistent issue with executing terminal commands in the current environment. Unfortunately, without the ability to run these commands, I am unable to download and install Python 3.12 directly.\\n\\nYou may need to manually download and install Python 3.12 from the [official Python website](https://www.python.org/downloads/release/python-3120/). If you have any questions or need further assistance, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 428, 'total_tokens': 519, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None}, id='run-2606b19e-6e26-4a78-8fb1-82169eb50ac3-0', usage_metadata={'input_tokens': 428, 'output_tokens': 91, 'total_tokens': 519, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})] \n",
      "\n",
      "{'past_steps': [('If Python 3.12 is not installed, download and install it from the official Python website.', 'It seems there is a persistent issue with executing terminal commands in the current environment. Unfortunately, without the ability to run these commands, I am unable to download and install Python 3.12 directly.\\n\\nYou may need to manually download and install Python 3.12 from the [official Python website](https://www.python.org/downloads/release/python-3120/). If you have any questions or need further assistance, feel free to ask!')]}\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\openai\\_base_client.py:1572\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1572\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m   1573\u001b[0m         request,\n\u001b[0;32m   1574\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m   1575\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1576\u001b[0m     )\n\u001b[0;32m   1577\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpx\\_client.py:1674\u001b[0m, in \u001b[0;36mAsyncClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m   1672\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m-> 1674\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m   1675\u001b[0m     request,\n\u001b[0;32m   1676\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m   1677\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m   1678\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m   1679\u001b[0m )\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpx\\_client.py:1702\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m   1701\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1702\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m   1703\u001b[0m         request,\n\u001b[0;32m   1704\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m   1705\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpx\\_client.py:1739\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[1;32m-> 1739\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m   1740\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpx\\_client.py:1776\u001b[0m, in \u001b[0;36mAsyncClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1776\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transport\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n\u001b[0;32m   1778\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:377\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 377\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py:256\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py:236\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhandle_async_request(\n\u001b[0;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpcore\\_async\\connection.py:103\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpcore\\_async\\http11.py:136\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpcore\\_async\\http11.py:106\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpcore\\_async\\http11.py:177\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpcore\\_async\\http11.py:217\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\httpcore\\_backends\\anyio.py:35\u001b[0m, in \u001b[0;36mAnyIOStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39mreceive(max_bytes\u001b[38;5;241m=\u001b[39mmax_bytes)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mEndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\anyio\\streams\\tls.py:204\u001b[0m, in \u001b[0;36mTLSStream.receive\u001b[1;34m(self, max_bytes)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreceive\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_bytes: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m65536\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_sslobject_method(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_object\u001b[38;5;241m.\u001b[39mread, max_bytes)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\anyio\\streams\\tls.py:147\u001b[0m, in \u001b[0;36mTLSStream._call_sslobject_method\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport_stream\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_bio\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m--> 147\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport_stream\u001b[38;5;241m.\u001b[39mreceive()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EndOfStream:\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\anyio\\_backends\\_asyncio.py:1227\u001b[0m, in \u001b[0;36mSocketStream.receive\u001b[1;34m(self, max_bytes)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mresume_reading()\n\u001b[1;32m-> 1227\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mread_event\u001b[38;5;241m.\u001b[39mwait()\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mpause_reading()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\locks.py:214\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5366\u001b[0m, in \u001b[0;36mRunnableBindingBase.ainvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5360\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mainvoke\u001b[39m(\n\u001b[0;32m   5361\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5362\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5363\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5364\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5365\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[0;32m   5367\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5369\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5370\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:307\u001b[0m, in \u001b[0;36mBaseChatModel.ainvoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m--> 307\u001b[0m llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[0;32m    308\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    309\u001b[0m     stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    310\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    311\u001b[0m     tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    312\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    313\u001b[0m     run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    314\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    316\u001b[0m )\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ChatGeneration, llm_result\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:796\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    795\u001b[0m prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[0;32m    797\u001b[0m     prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    798\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:722\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    712\u001b[0m run_managers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mon_chat_model_start(\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m    714\u001b[0m     messages,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[0;32m    720\u001b[0m )\n\u001b[1;32m--> 722\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m    724\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate_with_cache(\n\u001b[0;32m    725\u001b[0m             m,\n\u001b[0;32m    726\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    727\u001b[0m             run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    728\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    729\u001b[0m         )\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages)\n\u001b[0;32m    731\u001b[0m     ],\n\u001b[0;32m    732\u001b[0m     return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    733\u001b[0m )\n\u001b[0;32m    734\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:238\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n",
      "Cell \u001b[1;32mIn[16], line 31\u001b[0m, in \u001b[0;36mreplan_step\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplan_step\u001b[39m(state: PlanExecute):\n\u001b[1;32m---> 31\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m replanner\u001b[38;5;241m.\u001b[39mainvoke(state)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReplanner: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3068\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3068\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(part())\n\u001b[0;32m   3069\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n",
      "\u001b[1;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m}\n\u001b[0;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck to have python 3.12\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mastream(inputs, config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__end__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1865\u001b[0m, in \u001b[0;36mPregel.astream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1863\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1864\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1865\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39matick(\n\u001b[0;32m   1866\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1867\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1868\u001b[0m         retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1869\u001b[0m         get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1870\u001b[0m     ):\n\u001b[0;32m   1871\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[0;32m   1873\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\langgraph\\pregel\\runner.py:221\u001b[0m, in \u001b[0;36mPregelRunner.atick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    219\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[0;32m    222\u001b[0m         t, retry_policy, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream, writer\u001b[38;5;241m=\u001b[39mwriter\n\u001b[0;32m    223\u001b[0m     )\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\langgraph\\pregel\\retry.py:118\u001b[0m, in \u001b[0;36marun_with_retry\u001b[1;34m(task, retry_policy, stream, writer)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\OneDrive\\Uni\\hackatum\\.venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:455\u001b[0m, in \u001b[0;36mRunnableSeq.ainvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 455\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\"input\": \"Check to have python 3.12\"}\n",
    "async for event in app.astream(inputs, config=config):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
